"""
Deveoped by Hikmet Can Ã‡ubukÃ§u 
Biologicalâ€‘Variation Calculator (Streamlit)
==========================================
This singleâ€‘file Streamlit application helps a laboratory scientist calculate:

* **CV_A** â€“ analytical imprecision
* **CV_I** â€“ withinâ€‘subject biological variation (+95Â % CI)
* **CV_G** â€“ betweenâ€‘subject biological variation
* **RCV** â€“ twoâ€‘sided 95Â % referenceâ€‘change value

It implements the *balanced* twoâ€‘level varianceâ€‘component algebra of **RÃ¸raasÂ etÂ al. (2012)**.

v5 highlights
-------------
* **Deep inline commentary** â€“ every major line now has a `#` explanation so readers can
  follow both the Streamlit UI and the statistical maths.
* Template download in **CSV & XLSX** formats.
* Three dataâ€‘entry modes: *upload*, *paste*, *manual table*.

Run locally
-----------
```bash
pip install streamlit pandas numpy scipy openpyxl
streamlit run bv_streamlit.py
```
"""

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 0.  Imports & general setup
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
from __future__ import annotations   # futureâ€‘proof typing (PEP 563 style semantics)

import io                                # inâ€‘memory byte streams for XLSX template
import textwrap                          # clean multiâ€‘line strings for CSV template
from dataclasses import dataclass, field    # convenient result bundle
import numpy as np                       # scientific numberâ€‘crunching
import pandas as pd                      # tabular data handling
import streamlit as st                   # web UI framework
from scipy.stats import chi2 , t            # chiâ€‘square for exact CI of variance
from scipy.stats import shapiro, kstest, f              # normality + Cochran
from scipy.stats import bartlett, linregress  
import plotly.graph_objects as go   # â† NEW

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1.  Streamlit page config (title, layout)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Page configuration
st.set_page_config(
    page_title="Biological Variation Calculator",  # shown in browser tab
    layout="wide",
    initial_sidebar_state="expanded"                           # slim white gutter L/R
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# A.  Simple design system (tailwind-ish utility CSS)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Minimalistic CSS with enhanced heading
# Skeuomorphic CSS with white page background
st.markdown(
    """
    <style>
      /* Page background: plain white */
      body {
        background: #ffffff;
      }
      .block-container {
        padding: 2rem; 
        background: #ffffff;
        border: 1px solid #b0c4de;
        border-radius: 1rem;
        box-shadow: inset 0 1px 2px rgba(255,255,255,0.8), 0 4px 6px rgba(0,0,0,0.05);
        font-family: 'Georgia', serif;
        max-width: 900px;
        margin: 2rem auto;
      }
      /* Embossed heading in blue tones */
      h1 {
        text-align: center;
        font-size: 3rem;
        color: #1e3a5f;
        text-shadow: 1px 1px 2px rgba(255,255,255,0.7), -1px -1px 2px rgba(0,0,0,0.1);
        margin-bottom: 2rem;
      }
      /* Skeuomorphic metric cards with blue gradients */
      .metric-card {
        background: linear-gradient(145deg, #e8f4fd, #d0eaff);
        border-radius: 1rem;
        padding: 1.25rem;
        box-shadow: 4px 4px 8px rgba(0,0,0,0.1), inset 2px 2px 4px rgba(255,255,255,0.9);
        text-align: center;
        border: 1px solid #a3cce3;
      }
      .metric-title {
        font-size: 0.75rem;
        color: #28527a;
        text-transform: uppercase;
        letter-spacing: 0.05em;
        margin-bottom: 0.5rem;
        text-shadow: 0 1px 1px rgba(255,255,255,0.9);
      }
      .metric-value {
        font-size: 2rem;
        color: #1b263b;
        font-weight: bold;
        text-shadow: 0 1px 1px rgba(255,255,255,0.8);
      }
      .metric-delta {
        font-size: 0.85rem;
        color: #3e5c76;
        margin-top: 0.5rem;
      }
      /* Button styles: soft blue sheen */
      .stButton>button {
        background: linear-gradient(145deg, #b8d6f6, #95c5f0);
        border-radius: 0.75rem;
        border: 1px solid #7fa6d8;
        padding: 0.75rem 1.5rem;
        box-shadow: 3px 3px 6px rgba(0,0,0,0.1), inset 2px 2px 4px rgba(255,255,255,0.8);
        font-family: 'Georgia', serif;
        color: #1e3a5f;
        font-weight: bold;
      }
      .stButton>button:hover {
        background: linear-gradient(145deg, #95c5f0, #b8d6f6);
      }
      /* DataFrame container */
      .stDataFrame {
        border: 1px solid #b0c4de;
        border-radius: 0.75rem;
        box-shadow: inset 0 1px 2px rgba(255,255,255,0.8);
      }
      .stDataFrame thead tr th {
        background: #d0e7f5;
        color: #1e3a5f;
        text-shadow: 0 1px 1px rgba(255,255,255,0.9);
      }
    </style>
    """,
    unsafe_allow_html=True
)

# â”€â”€â”€ custom exception that stores the log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PreprocessError(ValueError):
    """Raised when the cleaner rejects the entire dataset.

    Attributes
    ----------
    log : list[str]
        The chronological quality-improvement log generated up to the
        failure point.  This lets the UI display what happened.
    """
    def __init__(self, msg: str, log: list[str]):
        super().__init__(msg)
        self.log = log

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2.  Dataclass to hold all computed results
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@dataclass
class BVResult:
    """Container for variance components and derived metrics."""

    # experiment counts
    I: int      # subjects
    S: int      # samples per subject
    R: int      # replicates per sample

    # mean of all raw results â€“ needed for CV calculation
    grand_mean: float

    # variance components (sigmaâ€‘squared)
    var_A: float   # analytical
    var_WP: float  # withinâ€‘person
    var_BP: float  # betweenâ€‘person

    # coefficients of variation (%)
    cv_A: float
    cv_I: float
    cv_G: float

    ci_mean:  tuple[float, float]       # 95â€¯% CI on grand mean
    ci_cv_A:  tuple[float, float]       # 95â€¯% CI on CV_A

    # confidence intervals & RCV
    ci_cv_I: tuple[float, float]  # (lower, upper) on CV_I
    ci_cv_G: tuple[float, float]  # (lower, upper) on CV_G   â† new
    rcv_95: float                 # % change considered significant (95 %)

    # NEW â€“ verbose audit trail of what happened during cleaning
    preprocess_log: list[str] = field(default_factory=list)
    
    # NEW â€“ optional CV-ANOVA estimates
    cv_I_cv_anova: float | None = None
    ci_cv_I_cv_anova: tuple[float, float] | None = None


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2-bis.  Column-mapping helpers
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
_DEFAULT_GUESSES = {
    "Subject":   ("subject", "patient", "participant", "id", "birey"),
    "Sample":    ("sample", "time", "visit", "Ã¶rnek"),
    "Replicate": ("rep", "replicate", "duplicate"),
    "Result":    ("result", "value", "measurement", "sonuÃ§", "deÄŸer"),
}

def _default_idx(role: str, cols: list[str]) -> int:
    """Return index in *cols* whose cleaned name matches expected role."""
    keys = _DEFAULT_GUESSES[role]
    for i, c in enumerate(cols):
        if str(c).strip().lower().replace(" ", "") in keys:
            return i
    return 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: remove any index column accidentally read as data
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _strip_ghost_index(df: pd.DataFrame) -> pd.DataFrame:
    """
    If the leftâ€‘most column is unnamed ('' or starts with 'Unnamed'),
    drop it and return the cleaned DataFrame.
    """
    if not df.empty and (df.columns[0] == "" or df.columns[0].startswith("Unnamed")):
        return df.iloc[:, 1:]
    return df

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3-bis.  Bragaâ€“Panteghini flow-chart utilities
#        (outlier tests + distribution checks)  :contentReference[oaicite:0]{index=0}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

from collections import namedtuple
CochranResult = namedtuple("CochranResult", "flag G G_crit")

def _cochrans_test(variances: np.ndarray,
                   alpha: float = 0.05,
                   df: int = 1) -> CochranResult:
    """
    Perform Cochranâ€™s C test and *return both* the decision and
    the two key statistics so the caller can log them.

    Returns
    -------
    CochranResult(flag, G, G_crit)
        flag : True  â†’ largest variance is an outlier
               False â†’ no outlier
    """
    k = variances.size
    if k < 2:
        return CochranResult(False, np.nan, np.nan)

    G = variances.max() / variances.sum()
    q = 1 - alpha / k                       # Å idÃ¡k
    f_crit = f.ppf(q, 1, (k - 1) * df)
    G_crit = f_crit / (f_crit + (k - 1))
    return CochranResult(G > G_crit, G, G_crit)

def _cochrans_test2(variances: np.ndarray,
                   alpha: float = 0.05,
                   df: int = 1) -> bool:
    """
    True  â†’ largest variance is a Cochran outlier and must be rejected
    False â†’ no Cochran outlier detected.
    """
    k = variances.size
    if k < 2:
        return False
    G = variances.max() / variances.sum()
    # critical limit from F-distribution (approximate Cochran)  :contentReference[oaicite:1]{index=1}
    q        = 1 - alpha / k
    f_crit   = f.ppf(q, 1, (k - 1) * df)
    G_crit   = f_crit / (f_crit + (k - 1))
    return G > G_crit


def _reed_outlier(values: np.ndarray) -> int | None:
    """
    Implements Reedâ€™s criterion:
    returns index in *values* of the outlier, or None if none found.
    """
    if values.size < 3:
        return None
    s_idx = np.argsort(values)
    s_val = values[s_idx]
    rng   = s_val[-1] - s_val[0]
    if rng == 0:
        return None
    # high-end
    if (s_val[-1] - s_val[-2]) > rng / 3:
        return int(s_idx[-1])
    # low-end
    if (s_val[1] - s_val[0]) > rng / 3:
        return int(s_idx[0])
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3-bis.  Data cleaning & quality-improvement pipeline
#         (Braga-Panteghini flow-chart, QI 7-10, Reed, Cochran, etc.)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _preprocess_bv_dataframe(
        df_in: pd.DataFrame,
        *,
        alpha: float = 0.05,
        normal_p: float = 0.05,
        enforce_balance: bool = True,
        flags: dict[str, bool] | None = None,          #  NEW
) -> tuple[pd.DataFrame, list[str]]:
    """
    Apply all pre-analysis quality-improvement (QI) checks and statistical
    filters required by Braga-Panteghini.  Returns a cleaned DataFrame **plus**
    a detailed chronological log (list of strings).
    """
    log: list[str] = []
    df = df_in.copy()
    transformed = False

    flags = flags or {}                    # safety â€“ empty dict if None
    ON     = lambda name: flags.get(name, True)   # helper: is this step enabled?

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 0.  Replicateâ€‘set consistency  (QIâ€¯8a â€“ Cochran variance test)
    #     â€¢ For every Subjectâ€‘Ã—â€‘Sample pair we calculate the variance of its
    #       replicate measurements.
    #     â€¢ Cochranâ€™s C identifies the pair whose variance is disproportionately
    #       large.  We iteratively remove offenders until the test is passed.
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # â”€â”€ QIâ€¯8a â€“ replicateâ€“set Cochran â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if ON("rep_cochran"):
        while True:
            rep_var = (df.groupby(["Subject", "Sample"])["Result"]
                        .var(ddof=1).dropna())
            if rep_var.size < 3:
                break

            R = (df.groupby(["Subject", "Sample"])["Replicate"]
                .nunique().mode().iat[0])          # current modal replicate count

            c_res = _cochrans_test(rep_var.values, alpha, df=R - 1)
            # â”€â”€ NEW universal log line â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log.append(
                f"QIâ€¯8a â€“ Cochran (replicate sets): "
                f"G = {c_res.G:.3f}, Gcrit = {c_res.G_crit:.3f}"
                + (" â†’ OUTLIER" if c_res.flag else " â†’ no outlier detected")
            )

            if not c_res.flag:          # test passed â†’ exit the loop
                break

            log.append(
                f"QIâ€¯8a â€“ Cochran test: G = {c_res.G:.3f}, "
                f"Gcrit = {c_res.G_crit:.3f}"
            )

            subj, samp = rep_var.idxmax()
            vals = df.loc[(df["Subject"] == subj) & (df["Sample"] == samp), "Result"]
            log.append(
                f"QIâ€¯8a â€“ replicate Cochran outlier removed â†’ "
                f"Subject {subj}, Sample {samp}: "
                + ", ".join(f"{v:.2f}" for v in vals) +
                f"  (sÂ² = {rep_var.max():.4f})"
            )
            df = df[~((df["Subject"] == subj) & (df["Sample"] == samp))]
    else:
        log.append("Replicate Cochran (QIâ€¯8a) skipped (switch off).")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‹ NEW: Bartlett's homogeneity test â€“ analytic variance (replicates)
    # Purpose: Are the replicate variances per SubjectÃ—Sample similar? 
    # (Is the analytic imprecison homogeneous across all samples?)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if ON("rep_bartlett"):

        valid_groups = []
        group_keys    = []                        # (Subject, Sample) anahtarlarÄ±nÄ± da tut
        for (subj, samp), g in df.groupby(["Subject", "Sample"]):
            if g["Result"].size < 2:              # Bartlett iÃ§in â‰¥2 Ã¶lÃ§Ã¼m ÅŸart
                continue
            if g["Result"].var(ddof=1) == 0:      # Excel: sÂ² = 0 olan Ã§iftleri hariÃ§ tutar
                continue
            valid_groups.append(g["Result"].values)
            group_keys.append((subj, samp))

        if len(valid_groups) >= 3:                # Bartlett â‰¥3 grup ister
            with np.errstate(all="ignore"):       # sabit giriÅŸ uyarÄ±larÄ±nÄ± bastÄ±r
                bart_stat, bart_p = bartlett(*valid_groups)
            rep_msg = "heterogeneous" if bart_p < alpha else "homogeneous"
            k = len(valid_groups)
            chi_crit = chi2.ppf(1 - alpha, k - 1)

            log.append(
                f"QIâ€¯8a â€“ Bartlett test (replicate sets): "
                f"Ï‡Â² = {bart_stat:.2f}, Ï‡Â²crit = {chi_crit:.2f}, "
                f"p = {bart_p:.4f} â†’ variances {rep_msg}."
            )

            # Excelâ€™de olduÄŸu gibi: heterojen ise en yÃ¼ksek 5 sÂ²â€™yi raporla
            if bart_p < alpha:
                rep_var = (df.groupby(["Subject", "Sample"])["Result"]
                            .var(ddof=1)
                            .loc[group_keys])     # yalnÄ±zca teste giren Ã§iftler
                top_bad = rep_var.sort_values(ascending=False).head(5)
                for (subj, samp), v in top_bad.items():
                    log.append(
                        f"  High analytical variance â†’ "
                        f"Subject {subj}, Sample {samp}  (sÂ² = {v:.4f})"
                    )
        else:
            log.append(
                "QIâ€¯8a â€“ Bartlett test (replicate sets) skipped: "
                "fewer than 3 valid replicate groups."
            )
    else:
        log.append("Replicate Bartlett (QIâ€¯8a) skipped (switch off).")

    # â”€â”€ QIâ€¯8b â€“ sampleâ€‘level Cochran inside each subject â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if ON("samp_cochran"):

        changed = True
        while changed:
            changed = False
            for subj, g in df.groupby("Subject"):

                samp_var = g.groupby("Sample")["Result"].var(ddof=1).dropna()

                # (3) ensure we log even when the test is impossible
                if samp_var.size < 3:
                    log.append(f"QIâ€¯8b â€“ Cochran skipped (Subject {subj}): <3 variances.")
                    continue

                r_per_sample = g.groupby("Sample")["Replicate"].nunique().mode().iat[0]

                # (2) Cochran undefined if only one replicate
                if r_per_sample < 2:
                    log.append(f"QIâ€¯8b â€“ Cochran skipped (Subject {subj}): only 1 replicate.")
                    continue

                c_res = _cochrans_test(samp_var.values, alpha, df=r_per_sample - 1)

                # single universal log line
                log.append(
                    f"QIâ€¯8b â€“ Cochran (Subject {subj}): "
                    f"G = {c_res.G:.3f}, Gcrit = {c_res.G_crit:.3f}"
                    + (" â†’ OUTLIER" if c_res.flag else " â†’ no outlier detected")
                )

                if not c_res.flag:
                    continue  # nothing to remove â€“ next subject

                # remove the offending sample
                samp = samp_var.idxmax()
                vals = df.loc[(df["Subject"] == subj) & (df["Sample"] == samp), "Result"]
                log.append(
                    f"QIâ€¯8b â€“ sample Cochran outlier removed â†’ "
                    f"Subject {subj}, Sample {samp}: "
                    + ", ".join(f"{v:.2f}" for v in vals) +
                    f"  (sÂ² = {samp_var.max():.4f})"
                )
                df = df[~((df["Subject"] == subj) & (df["Sample"] == samp))]
                changed = True
                break   # restart because groupby cache is stale
    else:
        log.append("Sample Cochran (QIâ€¯8b) skipped (switch off).")

    # â”€â”€ QIâ€¯8c â€“ betweenâ€‘subject Reed test only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if ON("reed"):

        removed_any = False          # â‘  NEW â€“ keeps track of removals

        while True:
            subj_mean = df.groupby("Subject")["Result"].mean()
            ridx      = _reed_outlier(subj_mean.values)

            if ridx is None:
                # no new outlier found â†’ exit loop â€¦
                if not removed_any:  # â‘¡ NEW â€“ log only if the very first check already passed
                    log.append("QIâ€¯8c â€“ Reed test passed: no betweenâ€‘subject outliers.")
                break

            removed_any = True       # mark that we did remove something

            culprit = subj_mean.index[ridx]
            vals    = df.loc[df["Subject"] == culprit, "Result"]

            log.append(
                f"QIâ€¯8c â€“ Reed mean outlier â†’ removed Subject {culprit} "
                f"(mean = {subj_mean.iloc[ridx]:.2f}; values: "
                + ", ".join(f"{v:.2f}" for v in vals) + ")"
            )
            df = df[~df["Subject"].eq(culprit)]
    else:
        log.append("Reed betweenâ€‘subject (QIâ€¯8c) skipped (switch off).")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 0â€¯b.  Steadyâ€‘state trend test (QIâ€¯7) â€“ slope Â±â€¯95â€¯%â€¯CI
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if ON("drift"):

        tinv = lambda p, df: abs(t.ppf(p/2, df))        # twoâ€‘sided tâ€‘quantile
        drift_records = []                               # list of dicts

        for subj, g in df.groupby("Subject"):
            # need at least three timeâ€‘points for a slope
            if g["Sample"].nunique() <= 2:
                continue

            res = linregress(g["Sample"], g["Result"])
            df_denom = len(g) - 2                       # regression d.f.
            if df_denom <= 0:
                continue

            ts = tinv(0.05, df_denom)                   # 95â€¯% twoâ€‘sided
            ci_low  = res.slope - ts * res.stderr
            ci_high = res.slope + ts * res.stderr

            if res.pvalue < 0.05:                       # significant drift
                drift_records.append(
                    dict(subj=subj,
                        slope=res.slope,
                        p=res.pvalue,
                        ci=(ci_low, ci_high))
                )

        # â”€â”€ write log + drop drifting subjects *once* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if drift_records:
            for d in drift_records:
                log.append(
                    "QI 7 â€“ temporal drift: Subject {subj} slope = {s:+.3g} "
                    "(95â€¯%â€¯CI {lo:.3g}â€“{hi:.3g}, p = {p:.3g}) â€“ excluded."
                    .format(subj=d["subj"], s=d["slope"],
                            lo=d["ci"][0], hi=d["ci"][1], p=d["p"])
                )

            df = df[~df["Subject"].isin([d["subj"] for d in drift_records])]
            log.append(f"Total subjects excluded for drift (QIâ€¯7): {len(drift_records)}")

    else:
        log.append("Steadyâ€‘state drift (QIâ€¯7) skipped (switch off).")


    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2.  Normality assessment  (subject-level  +  subject-means)   âŸ¨QI 9âŸ©
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if ON("normality"):

        def _fraction_subjects_normal(d: pd.DataFrame) -> tuple[int, int]:
            """
            Return (n_gaussian, n_eligible) where â€œeligibleâ€ means â‰¥3 results/subject.
            Gaussianity is Shapiro-Wilk p-value > normal_p on raw results.
            """
            good, total = 0, 0
            for _, g in d.groupby("Subject"):
                if g["Result"].size >= 3:
                    total += 1
                    if shapiro(g["Result"])[1] > normal_p:
                        good += 1
            return good, total

        # â”€â”€ 2-a. Shapiro-Wilk on each subject (raw scale) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        n_good, n_total = _fraction_subjects_normal(df)
        if n_total:
            frac_txt = f"{n_good}/{n_total} subjects ({n_good/n_total:.0%})"
            log.append(
                f"Normality check (QI 9) â€“ {frac_txt} passed Shapiro-Wilk "
                f"p>{normal_p} on raw results."
            )
        else:
            log.append("Normality check (QI 9) â€“ skipped (too few subjects).")

        if n_total and n_good / n_total <= 0.50:
            df["Result"] = np.log(df["Result"])
            transformed  = True
            log.append("Natural-log transform applied â€“ <50 % of subjects were Gaussian.")

        # â”€â”€ 2â€‘b. Shapiroâ€‘Wilk on subject means (always if â‰¥3 subjects) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        means = df.groupby("Subject")["Result"].mean()
        if means.size >= 3:
            p_sw = shapiro(means)[1]
            log.append(f"Subjectâ€‘means Shapiro-Wilk p = {p_sw:.3g}.")
            
            if p_sw <= normal_p and not transformed:
                # one chance: logâ€‘transform the whole dataset
                df["Result"] = np.log(df["Result"])
                transformed  = True
                log.append("Naturalâ€‘log transform applied after subjectâ€‘mean SW failure.")
                means = df.groupby("Subject")["Result"].mean()
                if shapiro(means)[1] <= normal_p:
                    raise ValueError("Normality could not be achieved â€“ stopping.")
            elif p_sw <= normal_p:
                raise ValueError("Normality could not be achieved even after logâ€‘transform.")
    else:
        log.append("Normality checks / logâ€‘transform (QIâ€¯9) skipped (switch off).")  

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3.  Variance-homogeneity across subjects (Bartlett, QI 10)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#    if df["Subject"].nunique() >= 2:
#        bart_p = bartlett(*[g["Result"].values for _, g in df.groupby("Subject")])[1]
#        msg    = ("heterogeneous" if bart_p < 0.05 else "homogeneous")
#        log.append(f"Bartlett test (QI 10): p = {bart_p:.3g} â†’ variances {msg}.")
#    else:
#        log.append("Bartlett test skipped â€“ fewer than two subjects remain.")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3.  Varianceâ€‘homogeneity *across subjects*  (Bartlett, QIâ€¯10Â â€“ Excel uyumlu)
    #     Excel mantÄ±ÄŸÄ±:
    #       â‘  Her denekte (Subject) Ã¶nce replicates ortalamasÄ± alÄ±nÄ±r â†’
    #          her Ã¶rnek (Sample) tek bir deÄŸere iner â†’ analitik gÃ¼rÃ¼ltÃ¼ elenir.
    #       â‘¡ AynÄ± deneÄŸin â‰¥2 Ã¶rneÄŸi varsa bunlarÄ±n varyansÄ± sÂ²_WP hesaplanÄ±r.
    #       â‘¢ Bartlett testi â‰¥3 deneklik {sÂ²_WP} kÃ¼mesine uygulanÄ±r.
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if ON("wp_bartlett"):

        subj_groups = []          # Bartlettâ€™e girecek her deneÄŸin â€œÃ¶rnek ortalamalarÄ±â€
        subj_keys   = []          # AynÄ± sÄ±rayla Subject ID tut (rapor logâ€™u iÃ§in)

        for subj, g in df.groupby("Subject"):
            if g["Sample"].nunique() < 2:      # Bartlett iÃ§in denek baÅŸÄ±na â‰¥2 Ã¶rnek gerek
                continue
            sample_means = g.groupby("Sample")["Result"].mean().values
            if sample_means.var(ddof=1) == 0:  # Excel: varyans sÄ±fÄ±rsa deneÄŸi test dÄ±ÅŸÄ± bÄ±rakÄ±r
                continue
            subj_groups.append(sample_means)
            subj_keys.append(subj)

        if len(subj_groups) >= 3:              # Bartlett â‰¥3 grup ister
            with np.errstate(all="ignore"):    # sabit grup uyarÄ±larÄ±nÄ± bastÄ±r
                bart_stat, bart_p = bartlett(*subj_groups)
            wp_msg = "heterogeneous" if bart_p < alpha else "homogeneous"
            k = len(subj_groups)
            chi_crit = chi2.ppf(1 - alpha, k - 1)

            log.append(
                f"QIâ€¯10 â€“ Bartlett test (withinâ€‘subject variances): "
                f"Ï‡Â² = {bart_stat:.2f}, Ï‡Â²crit = {chi_crit:.2f}, "
                f"p = {bart_p:.4f} â†’ variances {wp_msg}."
            )

            # If p < alpha, report the top 5 highest within-subject variances (sÂ²_WP)
            if bart_p < alpha:
                wp_var = {
                    subj: g.groupby("Sample")["Result"].mean().var(ddof=1)
                    for subj, g in df.groupby("Subject") if subj in subj_keys
                }
                for subj, v in sorted(wp_var.items(), key=lambda x: x[1], reverse=True)[:5]:
                    log.append(
                        f"  High withinâ€‘subject variance â†’ Subject {subj}  (sÂ² = {v:.4f})"
                    )
        else:
            log.append(
                "QIâ€¯10 â€“ Bartlett test (withinâ€‘subject variances) skipped: "
                "fewer than 3 eligible subjects."
            )
    else:
        log.append("Withinâ€‘subject Bartlett (QIâ€¯10) skipped (switch off).")  
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4.  Force a perfectly balanced design for the ANOVA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4.  Force a perfectly balanced design (equal S & R)
    #     â€“ required for the closed-form two-level ANOVA that follows
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â•â•â•â•â•â•â•â•â• 4.  Force a perfectly balanced design â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if enforce_balance:                                      # NEW GUARD

        # 4-a â–¸ SUBJECT-LEVEL balance  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        samp_cnt  = df.groupby("Subject")["Sample"].nunique()          # how many samples per subject
        target_S  = samp_cnt.mode().iat[0] if not samp_cnt.empty else 0

        off_subj  = samp_cnt[samp_cnt != target_S]                     # subjects that deviate
        if not off_subj.empty:
            for subj, nS in off_subj.items():
                log.append(
                    f"Balance check â€“ Subject **{subj}** contributes "
                    f"{nS}/{target_S} required samples; subject **excluded** to keep "
                    "a fully crossed design."
                )
            log.append(
                f"{len(off_subj)} subject(s) dropped because they lacked the modal "
                f"sample count *S = {target_S}*."
            )

        # retain only subjects with the correct sample count
        df = df[df["Subject"].isin(samp_cnt[samp_cnt == target_S].index)]

        # 4-b â–¸ SAMPLE-LEVEL balance  (replicate count)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rep_cnt  = (df.groupby(["Subject", "Sample"])["Replicate"]
                    .nunique()
                    .reset_index(name="n"))
        target_R = rep_cnt["n"].mode().iat[0] if not rep_cnt.empty else 0

        bad_pairs = rep_cnt[rep_cnt["n"] != target_R]
        if not bad_pairs.empty:
            for _, row in bad_pairs.iterrows():
                log.append(
                    f"Balance check â€“ Subject **{row.Subject}**, Sample **{row.Sample}** "
                    f"has {row.n}/{target_R} replicate measurements; sample **removed**."
                )
            log.append(
                f"{len(bad_pairs)} sample(s) discarded to enforce a uniform replicate "
                f"count *R = {target_R}* across all remaining subjects."
            )

        if not bad_pairs.empty:
            bad_idx = df.set_index(["Subject", "Sample"]).index.isin(
                bad_pairs.set_index(["Subject", "Sample"]).index)
            df = df[~bad_idx]


        # 4-c.  final sanity check
        I_fin = df["Subject"].nunique()
        if df.empty:
            raise PreprocessError(
                "All data were excluded by quality checks â€“ nothing left to analyse.",
                log,
            )
        S_fin = df.groupby("Subject")["Sample"].nunique().iloc[0]
        R_fin = (df.groupby(["Subject", "Sample"])["Replicate"].nunique().iloc[0])

        log.append(f"âœ… Balanced data set ready: {I_fin} subjects Ã— "
                f"{S_fin} samples Ã— {R_fin} replicates retained for ANOVA.")
        
    else:                                                    # NEW â”€ skip pruning
        log.append("âš ï¸ Balance enforcement skipped â€“ continuing with "
                   "unbalanced data; results will use the unbalanced formulas.")
        # â”€â”€â”€ NEW â–¶ log the FINAL numbers kept for analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        I_fin = df["Subject"].nunique()
        S_fin = df.groupby("Subject")["Sample"].nunique().mean()          # mean S
        R_fin = df.groupby(["Subject","Sample"])["Replicate"].nunique().mean()  # mean R
        log.append(
            f"âœ… Final data set (without enforcement for balanced crossed design): {I_fin} subjects, "
            f"mean {S_fin:.2f} samples/subject, "
            f"mean {R_fin:.2f} replicates/sample retained for ANOVA."
        )
        # -------------------------------------------------------------------

        # minimal sanity check
        if df.empty:
            raise PreprocessError("All data removed during QC.", log)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5.  Return cleaned data (back-transformed if needed) + log
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if transformed:
        df["Result"] = np.exp(df["Result"])

    return df, log



# CV ANOVA function
def _cvi_cv_anova(clean_df: pd.DataFrame, alpha: float = 0.05
) -> tuple[float, tuple[float, float]]:
    """
    CV-ANOVA as recommended by RÃ¸raas et al., 2016
    (see Clin Chem 62:725-736) :contentReference[oaicite:3]{index=3}
    -----------------------------------------------------------------
    1.  Divide every result by its subject-specific mean  â†’  CV-scale
    2.  Perform the usual two-level balanced ANOVA on the *normalised*
        values (mean â‰ˆ 1).
    3.  ÏƒÂ²_WP (within-person) on that scale âˆšâ†’ CVI (%).
    4.  Exact CI via Burdick & Graybill Ï‡Â² method (same df as classic).
    """
    df = clean_df.copy()
    df["Norm"] = df["Result"] / df.groupby("Subject")["Result"].transform("mean")

    I = df["Subject"].nunique()
    S = df.groupby("Subject")["Sample"].nunique().iloc[0]
    R = df.groupby(["Subject", "Sample"])["Replicate"].nunique().iloc[0]

    subj_mean = df.groupby("Subject")["Norm"].mean()                     # ~1
    samp_mean = df.groupby(["Subject", "Sample"])["Norm"].mean()

    ms_wp = R * ((samp_mean - subj_mean.loc[samp_mean.index.get_level_values(0)].values) ** 2
                 ).sum() / (I * (S - 1))
    ms_a  = ((df["Norm"] - samp_mean.loc[list(zip(df["Subject"], df["Sample"]))].values) ** 2
             ).sum() / (I * S * (R - 1))

    var_wp = max((ms_wp - ms_a) / R, 0.0)                # ÏƒÂ²_WP on CV scale
    cvi    = np.sqrt(var_wp) * 100                       # mean = 1 â†’ CVI %

    # -------- exact 95 % CI (same df as classic) ------------------
    df_wp  = I * (S - 1)
    chi_lo = chi2.ppf(alpha/2,     df_wp)
    chi_hi = chi2.ppf(1 - alpha/2, df_wp)

    ms_lo  = (df_wp * ms_wp) / chi_hi
    ms_hi  = (df_wp * ms_wp) / chi_lo

    ci_var_lo = max((ms_lo - ms_a) / R, 0.0)
    ci_var_hi = max((ms_hi - ms_a) / R, 0.0)
    ci        = (np.sqrt(ci_var_lo) * 100, np.sqrt(ci_var_hi) * 100)
    return cvi, ci


# ---------------------------------------------------------------------------
#  CVâ€‘ANOVA  â†’  unbalanced design
# ---------------------------------------------------------------------------
def _cvi_cv_anova_unbalanced(clean_df: pd.DataFrame,
                             alpha: float = 0.05
) -> tuple[float, tuple[float, float]]:
    """
    CVâ€‘ANOVA that tolerates unequal samplesâ€‘/replicatesâ€‘perâ€‘subject.

    Steps (RÃ¸raas 2016, adapted):

    1.  Normalise all results by each subjectâ€™s mean (â†’ mean â‰ˆâ€¯1).
    2.  Construct the unbalanced meanâ€“squares table with weights náµ¢â±¼.
    3.  ÏƒÂ²_WPÂ =Â (MS_WPÂ âˆ’Â MS_A)/È“      where È“Â =Â mean replicate count.
    4.  Exact CI uses Burdick &â€¯Graybill Ï‡Â² limits with dfÂ =Â Î£(Sáµ¢Â âˆ’Â 1).
    """
    df = clean_df.copy()
    df["Norm"] = df["Result"] / df.groupby("Subject")["Result"].transform("mean")

    # ------------------------------------------------------------------ weights
    r_ij = df.groupby(["Subject", "Sample"])["Replicate"].nunique()      # náµ¢â±¼
    r_bar = r_ij.mean()                                                 # È“

    subj_mean = df.groupby("Subject")["Norm"].mean()
    samp_mean = df.groupby(["Subject", "Sample"])["Norm"].mean()

    # â”€â”€ SS & MS (unbalanced) -----------------------------------------------
    ss_wp = ((samp_mean - samp_mean.index.get_level_values(0).map(subj_mean))**2 *
             r_ij).sum()
    df_wp = (df.groupby("Subject")["Sample"].nunique() - 1).sum()
    ms_wp = ss_wp / df_wp

    ss_a  = ((df["Norm"] -
              samp_mean.loc[list(zip(df["Subject"], df["Sample"]))].values)**2).sum()
    df_a  = (r_ij - 1).sum()
    ms_a  = ss_a / df_a

    var_wp = max((ms_wp - ms_a) / r_bar, 0.0)
    cvi    = np.sqrt(var_wp) * 100

    # â”€â”€ exact CI on ÏƒÂ²_WP ----------------------------------------------------
    chi_lo = chi2.ppf(alpha/2,     df_wp)
    chi_hi = chi2.ppf(1-alpha/2,  df_wp)

    ms_lo  = (df_wp * ms_wp) / chi_hi
    ms_hi  = (df_wp * ms_wp) / chi_lo

    var_lo = max((ms_lo - ms_a) / r_bar, 0.0)
    var_hi = max((ms_hi - ms_a) / r_bar, 0.0)
    ci     = (np.sqrt(var_lo)*100, np.sqrt(var_hi)*100)

    return cvi, ci


# â€”â€”â€” helper for the unbalanced branch â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def _calculate_bv_unbalanced(df: pd.DataFrame,
                             alpha: float = 0.05) -> dict[str, float]:
    """
    Replicates the Excel â€˜Glucose CVI and CVA â€“Â Allâ€™ workbook:

    â€¢ ÏƒÂ²_A   : pure analytical variance  = MS_A  
    â€¢ ÏƒÂ²_WP  : (MS_WPÂ â€“Â MS_A)â€¯/â€¯È“        where È“ is the *mean* replicate count  
    â€¢ ÏƒÂ²_BP  : (MS_BPÂ â€“Â MS_WP)â€¯/â€¯(ÅšÂ·È“)   Åš = *mean* samples/subject  

    CIs use the same Ï‡Â² limits as the balanced formula but with the actual
    d.f. from the unbalanced ANOVA table.
    """
    # raw counts per cell
    r_ij  = (df.groupby(["Subject", "Sample"])["Replicate"]
               .nunique())
    S_i   = df.groupby("Subject")["Sample"].nunique()

    r_bar = r_ij.mean()                      # È“
    S_bar = S_i.mean()                       # Åš

    # ---- ordinary nested MS table (works in unbalanced designs) ----------
    # NB: keep the sums as in the balanced code â€“ pandas handles the weights
    subj_mean = df.groupby("Subject")["Result"].mean()
    samp_mean = df.groupby(["Subject", "Sample"])["Result"].mean()
    grand     = df["Result"].mean()

    ss_bp = ((samp_mean.index.get_level_values(0).map(subj_mean) - grand)**2
              * r_ij).groupby(level=0).sum().sum()
    ss_wp = ((samp_mean - samp_mean.index.get_level_values(0).map(subj_mean))**2
              * r_ij).sum()
    ss_a  = ((df["Result"]
              - samp_mean.loc[list(zip(df["Subject"], df["Sample"]))].values)**2).sum()

    I  = subj_mean.size
    df_bp = I - 1
    df_wp = (S_i - 1).sum()
    df_a  = (r_ij - 1).sum()

    ms_bp, ms_wp, ms_a = ss_bp/df_bp, ss_wp/df_wp, ss_a/df_a

    var_A  = ms_a
    var_WP = max((ms_wp - ms_a)/r_bar, 0.0)
    var_BP = max((ms_bp - ms_wp)/(S_bar*r_bar), 0.0)

    cv_A = np.sqrt(var_A)/grand * 100
    cv_I = np.sqrt(var_WP)/grand * 100
    cv_G = np.sqrt(var_BP)/grand * 100

    # Ï‡Â² limits â€“ same idea, just the *unbalanced* d.f.
    chi = chi2
    ci_cv_A = (np.sqrt(var_A*df_a/chi.ppf(0.975, df_a))/grand*100,
               np.sqrt(var_A*df_a/chi.ppf(0.025, df_a))/grand*100)
    ci_cv_I = (np.sqrt(max(( (df_wp*ms_wp/chi.ppf(0.975,df_wp))-var_A)/r_bar,0))/grand*100,
               np.sqrt(max(( (df_wp*ms_wp/chi.ppf(0.025,df_wp))-var_A)/r_bar,0))/grand*100)
    ci_cv_G = (np.sqrt(max(( (df_bp*(ms_bp-ms_wp)/chi.ppf(0.975,df_bp)))/(S_bar*r_bar),0))/grand*100,
               np.sqrt(max(( (df_bp*(ms_bp-ms_wp)/chi.ppf(0.025,df_bp)))/(S_bar*r_bar),0))/grand*100)

    rcv = 1.96*np.sqrt(2)*np.sqrt(cv_A**2 + cv_I**2)

    return dict(var_A=var_A, var_WP=var_WP, var_BP=var_BP,
                cv_A=cv_A, cv_I=cv_I, cv_G=cv_G,
                ci_cv_A=ci_cv_A, ci_cv_I=ci_cv_I, ci_cv_G=ci_cv_G,
                rcv=rcv, grand=grand,
                df_bp=df_bp, df_wp=df_wp, df_a=df_a)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4.  Core calculation routine (closedâ€‘form RÃ¸raas algebra)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def calculate_bv(df: pd.DataFrame, alpha: float = 0.05,
                 use_cv_anova: bool = False,
                 enforce_balance: bool = True        # NEW PARAM
) -> BVResult:
    """Compute balancedâ€‘design variance components & CVs.

    Parameters
    ----------
    df : DataFrame
        Must contain at least the four columns: Subject, Sample, Replicate, Result.
        Extra columns are ignored. Capitalisation is normalised.
    alpha : float
        Significance level for the CI on CV_I (0.05 â†’ 95 % CI).
    """

    
    # 3.1 normalise column names to Titleâ€‘Case so user can type "subject" etc.
    df = df.rename(str.title, axis=1)
    required = {"Subject", "Sample", "Replicate", "Result"}
    if not required.issubset(df.columns):
        # fail fast if critical columns missing
        raise KeyError(f"Missing required columns: {required - set(df.columns)}")
    
    # â”€â”€ NEW â€“ capture raw study dimensions BEFORE any cleaning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    I0 = df["Subject"].nunique()
    S0 = df.groupby("Subject")["Sample"].nunique().mode().iat[0]
    R0 = df.groupby(["Subject", "Sample"])["Replicate"].nunique().mode().iat[0]
    # -------------------------------------------------------------------------
    # 3.1  apply Bragaâ€“Panteghini outlier/normality pipeline  
    try:
        df, pp_log = _preprocess_bv_dataframe(
            df, alpha=alpha, enforce_balance=enforce_balance, flags=st.session_state.get("preproc_flags"))   # NEW ARG
    except PreprocessError as e:
        # Propagate the cleanerâ€™s detailed log upward
        raise PreprocessError(str(e), e.log) from None

    # â”€â”€ NEW â€“ prepend the headline to the audit trail â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pp_log.insert(
        0,
        f"Uploaded data: {I0} subjects Ã— {S0} samples Ã— {R0} replicates "
        "(raw, before quality checks)."
    )
    # ------------------------------------------------------------------------

    if not enforce_balance:                                 # â”€â”€ unbalanced â”€â”€
        ub = _calculate_bv_unbalanced(df, alpha)

        # â”€â”€â”€ NEW â–¶ dataset counts & CI on the mean â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        I_u  = df["Subject"].nunique()
        S_u  = df.groupby("Subject")["Sample"].nunique().mean()   # meanâ€¯S
        R_u  = df.groupby(["Subject", "Sample"])["Replicate"].nunique().mean()  # meanâ€¯R

        N_tot  = len(df)
        sd_all = df["Result"].std(ddof=1)
        t_crit = t.ppf(1 - alpha/2, N_tot - 1)
        ci_mean_u = (ub["grand"] - t_crit * sd_all / np.sqrt(N_tot),
                     ub["grand"] + t_crit * sd_all / np.sqrt(N_tot))
        # log it
#        pp_log.append(
#            f"âœ… Unbalanced data set ready: {I_u} subjects Ã— "
#            f"mean {S_u:.2f} samples/subject Ã— "
#            f"mean {R_u:.2f} replicates/sample retained for ANOVA."
#        )
        pp_log.append("Unbalanced design â†’ variance components derived with "
                      "(methodâ€‘ofâ€‘moments) algebra.")
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # â–¶ optional CVâ€‘ANOVA on the *unbalanced* data
        cv_anova = ci_cv_anova = None
        if use_cv_anova:                                   # honour sidebar tick
            cv_anova, ci_cv_anova = _cvi_cv_anova_unbalanced(df, alpha)
            pp_log.append(
                f"CVI (CVâ€‘ANOVA, unbalanced) calculated: {cv_anova:.2f} % "
                f"(95Â %Â CI {ci_cv_anova[0]:.2f}â€“{ci_cv_anova[1]:.2f}Â %)."
            )

        return BVResult(
            I = int(I_u),
            S = S_u,
            R = R_u,
            grand_mean = ub["grand"],
            var_A = ub["var_A"],
            var_WP = ub["var_WP"],
            var_BP = ub["var_BP"],
            cv_A = ub["cv_A"],
            cv_I = ub["cv_I"],
            cv_G = ub["cv_G"],
            ci_mean = ci_mean_u,
            ci_cv_A = ub["ci_cv_A"],
            ci_cv_I = ub["ci_cv_I"],
            ci_cv_G = ub["ci_cv_G"],
            rcv_95 = ub["rcv"],
            preprocess_log = pp_log,
            cv_I_cv_anova = cv_anova,               # â† NEW
            ci_cv_I_cv_anova = ci_cv_anova          # â† NEW
        )


    else:  # balanced design â†’ use closedâ€‘form algebra

        # 3.2 derive counts (I, S, R) and assert balance
        I = df["Subject"].nunique()                                          # how many people
        S = df.groupby("Subject")["Sample"].nunique().iloc[0]               # samples per person
        R = df.groupby(["Subject", "Sample"])["Replicate"].nunique().iloc[0]  # replicates per sample

        # confirm every subject has S samples and every sample has R replicates
        if not (df.groupby("Subject")["Sample"].nunique() == S).all():
            raise ValueError("Unbalanced design: unequal samples per subject.")
        if not (
            df.groupby(["Subject", "Sample"])["Replicate"].nunique() == R
        ).all():
            raise ValueError("Unbalanced design: unequal replicates per sample.")

        # 3.3 overall mean â€“ denominator for CV (%).
        grand = df["Result"].mean()

        # ğŸ”¶ NEW â€” 95â€¯% CI on the mean ------------------------------
        N_tot  = len(df)
        sd_all = df["Result"].std(ddof=1)
        t_crit = t.ppf(1 - alpha/2, N_tot - 1)
        ci_mean = (grand - t_crit * sd_all / np.sqrt(N_tot),
                grand + t_crit * sd_all / np.sqrt(N_tot))
        # -----------------------------------------------------------

        # 3.4 means for each hierarchical level
        subj_mean = df.groupby("Subject")["Result"].mean()                   # \bar Y_{i..}
        samp_mean = df.groupby(["Subject", "Sample"])["Result"].mean()      # \bar Y_{is.}

        # 3.5 sumsâ€‘ofâ€‘squares according to EMS table (RÃ¸raas Eqâ€¯2)
        ss_bp = R * S * ((subj_mean - grand) ** 2).sum()                      # betweenâ€‘person
        ss_wp = R * (
            (samp_mean - subj_mean.loc[samp_mean.index.get_level_values(0)].values) ** 2
        ).sum()  # withinâ€‘person (samples)
        ss_a = (
            (df["Result"] - samp_mean.loc[list(zip(df["Subject"], df["Sample"]))].values) ** 2
        ).sum()  # replicate analytical error

        # 3.6 convert SS â†’ MS by dividing by appropriate degrees of freedom
        ms_bp = ss_bp / (I - 1)               # df = Iâ€‘1
        ms_wp = ss_wp / (I * (S - 1))         # df = I*(Sâ€‘1)
        ms_a = ss_a / (I * S * (R - 1))       # df = I*S*(Râ€‘1)

        # 3.7 backâ€‘solve variance components (closedâ€‘form)
        var_A = ms_a                                          # ÏƒÂ²_A
        var_WP = max((ms_wp - ms_a) / R, 0.0)                 # ÏƒÂ²_WP (truncate <0 to 0)
        var_BP = max((ms_bp - ms_wp) / (S * R), 0.0)          # ÏƒÂ²_BP

        # ğŸ”¶ NEW â€” 95â€¯% CI on CV_A  ---------------------------------
        df_a        = I * S * (R - 1)            # d.f. of MS_A
        chi_low_a   = chi2.ppf(alpha/2,     df_a)
        chi_up_a    = chi2.ppf(1-alpha/2,  df_a)
        ci_var_a_lo = var_A * df_a / chi_up_a
        ci_var_a_hi = var_A * df_a / chi_low_a
        ci_cv_A     = (np.sqrt(ci_var_a_lo) / grand * 100,
                    np.sqrt(ci_var_a_hi) / grand * 100)
        # -----------------------------------------------------------

        # 3.8 convert to CVs (%). grand mean in denominator.
        cv_A = np.sqrt(var_A) / grand * 100
        cv_I = np.sqrt(var_WP) / grand * 100
        cv_G = np.sqrt(var_BP) / grand * 100

        # 3.9 exact 95 % CI for CV_I using Burdick & Graybillâ€™s method
        df_wp = I * (S - 1)

        # twoâ€tailed Ï‡Â² quantiles
        chi2_lower_q = chi2.ppf(alpha/2, df_wp)       # e.g. 0.025 quantile
        chi2_upper_q = chi2.ppf(1 - alpha/2, df_wp)   # e.g. 0.975 quantile

        # limits on MS_WP
        ms_wp_lower = (df_wp * ms_wp) / chi2_upper_q
        ms_wp_upper = (df_wp * ms_wp) / chi2_lower_q

        # convert MS limits to ÏƒÂ²_WP limits: (MS_limit âˆ’ ÏƒÂ²_A) Ã· R
        ci_var_low = max((ms_wp_lower - var_A) / R, 0.0)
        ci_var_up  = max((ms_wp_upper - var_A) / R, 0.0)

        # finally back-transform to %CV
        ci_cv_I = (
            np.sqrt(ci_var_low) / grand * 100,
            np.sqrt(ci_var_up)  / grand * 100,
        )

        # â€” 3.10 exact 95 % CI for CV_G (between-subject) â€”â€”
        df_bp = I - 1
        chi2_low_bp = chi2.ppf(alpha/2, df_bp)
        chi2_up_bp  = chi2.ppf(1 - alpha/2, df_bp)

        # MS_BP contains ÏƒÂ²_A + RÏƒÂ²_WP + SRÏƒÂ²_BP; subtract lower levels first
        adj_ms_bp = ms_bp - ms_wp

        ms_bp_lower = (df_bp * adj_ms_bp) / chi2_up_bp
        ms_bp_upper = (df_bp * adj_ms_bp) / chi2_low_bp

        # convert MS limits to ÏƒÂ²_BP limits: MS_limit / (S*R)
        ci_var_bp_low = max(ms_bp_lower / (S * R), 0.0)
        ci_var_bp_up  = max(ms_bp_upper / (S * R), 0.0)

        ci_cv_G = (
            np.sqrt(ci_var_bp_low) / grand * 100,
            np.sqrt(ci_var_bp_up)  / grand * 100,
        )

        # 3.11 referenceâ€‘change value (twoâ€‘sided, 95Â %)
        rcv = 1.96 * np.sqrt(2) * np.sqrt(cv_A**2 + cv_I**2)
        
        # âŸ¨QI-6âŸ© analytical imprecision â€“ put a note into the audit trail
        pp_log.append(
            f"QI 6 â€“ analytical imprecision calculated: CVâ‚ = {cv_A:.2f} % "
            f"(based on R = {R} replicate(s)/sample)."
        )

        # --- after the classic CV calculations are finished -----------------
        cv_anova = ci_cv_anova = None
        if use_cv_anova:
            cv_anova, ci_cv_anova = _cvi_cv_anova(df, alpha)
            pp_log.append(
                f"CVI (CV-ANOVA) calculated: {cv_anova:.2f} % "
                f"(95 % CI {ci_cv_anova[0]:.2f}â€“{ci_cv_anova[1]:.2f} %)."
            )

        return BVResult(
            I, S, R, grand,
            var_A, var_WP, var_BP,
            cv_A, cv_I, cv_G,
            ci_mean,          # add here
            ci_cv_A,          # add here
            ci_cv_I, ci_cv_G, rcv,
            preprocess_log = pp_log,
            cv_I_cv_anova = cv_anova,
            ci_cv_I_cv_anova = ci_cv_anova,
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Beautiful per-subject mean Â± range (minâ€“max) plot
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def plot_subject_ranges(clean_df: pd.DataFrame) -> go.Figure:
    """
    Build a compact, minimalistic plot:

    â€¢ X-axis  â†’ Subject IDs (only those that survived cleaning)  
    â€¢ Y-axis  â†’ Result scale (mean â€¢, minâ€“max whisker)

    Returns
    -------
    plotly.graph_objects.Figure
    """
    # â”€â”€ summarise data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    agg = (clean_df.groupby("Subject")["Result"]
                  .agg(mean="mean", min="min", max="max")
                  .sort_index()
                  .reset_index())

    agg["err_low"]  = agg["mean"] - agg["min"]
    agg["err_high"] = agg["max"]  - agg["mean"]

    # create user-friendly x-labels (e.g. â€œSubject 7â€)
    agg["x_label"] = agg["Subject"].astype(str).apply(lambda s: f"Subject {s}")

    # â”€â”€ figure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig = go.Figure(
        go.Scatter(
            x=agg["x_label"],
            y=agg["mean"],
            mode="markers",
            marker=dict(size=6, color="#2a3f5f"),
            error_y=dict(
                type="data",
                symmetric=False,
                array=agg["err_high"],
                arrayminus=agg["err_low"],
                color="#9ea4ae",
                thickness=1,
                width=0            # no caps â†’ thin minimal whisker
            ),
            hovertemplate=(
                "%{x}<br>"
                "Mean %{y:.2f}<br>"
                "Range %{customdata[0]:.2f} â€“ %{customdata[1]:.2f}"
                "<extra></extra>"
            ),
            customdata=agg[["min", "max"]],
        )
    )

    # â”€â”€ styling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig.update_layout(
        template="simple_white",
        height=300 if len(agg) <= 8 else 360,      # stays small
        margin=dict(l=50, r=10, t=30, b=60),
        xaxis=dict(
            title="",              # no title; labels self-explanatory
            tickangle=-45,         # slanted for readability
            tickfont=dict(size=11),
            showgrid=False
        ),
        yaxis=dict(
            title="Result",
            zeroline=False,
            showgrid=False,
            ticks="outside",
            ticklen=4,
            tickcolor="#bfc1c4"
        ),
        font=dict(size=11),
        title=dict(
            text="Per-subject mean Â± range",
            x=0.5, xanchor="center",
            font=dict(size=14, color="#2a3f5f")
        ),
        hoverlabel=dict(bgcolor="white", font_size=11),
        showlegend=False
    )

    return fig

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 5.  Prepare template datasets for users to download (CSV & XLSX)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def get_template_df(
    num_subjects: int   = 40,
    num_samples:  int   = 5,
    num_replicates: int = 2,
) -> pd.DataFrame:
    """
    Generate a synthetic, yet perfectly balanced, study-design template.

    â€¢ Every subject has *num_samples* time-points / samples  
    â€¢ Every sample is analysed in duplicate (2 replicates)  
    â€¢ Results follow a simple deterministic pattern so the file is
      reproducible and easy to eyeball:  
          base = 100 + subject_index  
          result = base + sample_index + (replicate_index-1)
    """
    rows = []
    for s_idx in range(1, num_subjects + 1):
        subj_id = f"P{s_idx:02d}"          # P01, P02, â€¦, P40
        base    = 100 + s_idx              # gives between-subject spread
        for sample in range(1, num_samples + 1):
            for rep in range(1, num_replicates + 1):
                result = base + sample + (rep - 1)   # tiny within-sample shift
                rows.append((subj_id, sample, rep, result))

    return pd.DataFrame(
        rows, columns=["Subject", "Sample", "Replicate", "Result"]
    )

# 4.1 build inâ€‘memory CSV & XLSX once; reuse for all download clicks
_template_df = get_template_df()
_template_csv = _template_df.to_csv(index=False)           # plain text string
_template_xlsx_io = io.BytesIO()
with pd.ExcelWriter(_template_xlsx_io, engine="openpyxl") as xl_writer:
    _template_df.to_excel(xl_writer, sheet_name="Template", index=False)
_template_xlsx_io.seek(0)  # reset file pointer for download

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 6.  Streamlit user interface
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# 6.1  headline
st.title("Biological Variation Calculator")

# 6.2  sidebar â€“ quick help & template downloads
with st.sidebar:
    st.header("Quick start")
    st.write(
        "1. Upload or paste your balanced study file (CSV/XLSX)\n"
        "2. Map the four required columns\n"
        "3. Click on **Calculate** button"
    )
    st.divider()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Preâ€‘processing switches â€“ default = all ON
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.sidebar.subheader("Preâ€‘processing steps")

    PREPROC_OPTS = {
        # label                        internal key            default
        "Replicate Cochran (QIâ€¯8a)"  : ("rep_cochran",          True),
        "Replicate Bartlett (QIâ€¯8a)" : ("rep_bartlett",         True),
        "Sample Cochran (QIâ€¯8b)"     : ("samp_cochran",         True),
        "Reed betweenâ€‘subject (QIâ€¯8c)":("reed",                 True),
        "Steadyâ€‘state drift (QIâ€¯7)"  : ("drift",                True),
        "Normality checks / logâ€‘transform (QIâ€¯9)"
                                    : ("normality",           True),
        "Withinâ€‘subject Bartlett (QIâ€¯10)"
                                    : ("wp_bartlett",         True),
    }

    # build the checkâ€‘boxes and stash the chosen flags in session_state
    preproc_flags = {}
    for label, (key, default) in PREPROC_OPTS.items():
        preproc_flags[key] = st.sidebar.checkbox(label, value=default)
    st.session_state["preproc_flags"] = preproc_flags

    # Crossed design balance enforcement
    st.sidebar.subheader("Analysis options")                    # NEW
    enforce_balance = st.sidebar.checkbox(                      # NEW
        "Enforce balanced crossed design",                      # NEW
        value=True,                                             # NEW (default keeps old behaviour)
    )                                                           # NEW
    st.session_state["enforce_balance"] = enforce_balance       # NEW

    st.subheader("Need an example file?")
    with open('./template/bv_data_template.xlsx', "rb") as template_file:
        template_byte = template_file.read()
    # download template excel file
    st.download_button(label="â¬‡ï¸ Click to Download Template File",
                        data=template_byte,
                        file_name="template.xlsx",
                        mime='application/octet-stream')
    st.write("---")
    st.info('*Developed by Hikmet Can Ã‡ubukÃ§u, MD, PhD, MSc, EuSpLM* <hikmetcancubukcu@gmail.com>')


# 6.3 three tabs â€“ three dataâ€‘entry modes
upload_tab, entry_tab = st.tabs(["Upload", "Manual Entry"])

# NEW â–¸ make sure the variable always exists
user_df: pd.DataFrame | None = None

# -- Tab 1: Upload -----------------------------------------------------------
with upload_tab:
    up_file = st.file_uploader("Upload CSV or XLSX", type=["csv", "xlsx"])
    if up_file is not None:
        try:
            if up_file.name.lower().endswith("xlsx"):
                user_df = pd.read_excel(up_file)
            else:
                user_df = pd.read_csv(up_file)

            # NEW âœ strip accidental index column
            user_df = _strip_ghost_index(user_df)

            st.success("File loaded âœ“ â€“ please review below.")
        except Exception as e:
            st.error(f"Load error: {e}")


# â€” Tab 2: Manual Entry â€”
with entry_tab:
    st.write("Doubleâ€‘click to edit cells. Use the â• menu on the right to add rows.")

    # store editable df in session_state so edits persist across reruns
    if "manual_df" not in st.session_state:
        st.session_state.manual_df = _template_df.head(2)  # tiny starter grid

    manual_df = st.data_editor(
        st.session_state.manual_df,
        num_rows="dynamic",         # allow row addition
        use_container_width=True,
        key="editor",
    )
    if manual_df.dropna().shape[0] >= 4:
        user_df = _strip_ghost_index(manual_df.copy())
    # save edits back to session
    st.session_state.manual_df = manual_df


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 7. Preview & calculate button
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if user_df is not None:
    st.subheader("Data preview")
    st.dataframe(user_df, use_container_width=True, hide_index=True)


    # â€” Column mapping (collapsed until user opens it) â€”
    with st.expander("â‡¢  Map / confirm columns", expanded=False):
        cols = list(user_df.columns)
        with st.form("map_form"):
            c1, c2 = st.columns(2)
            with c1:
                subj_sel = st.selectbox("Subject identifier",  cols,
                                        index=_default_idx("Subject", cols))
                samp_sel = st.selectbox("Sample / time-point", cols,
                                        index=_default_idx("Sample", cols))
            with c2:
                repl_sel = st.selectbox("Replicate",          cols,
                                        index=_default_idx("Replicate", cols))
                res_sel  = st.selectbox("Result / value",     cols,
                                        index=_default_idx("Result", cols))

            confirmed = st.form_submit_button("Save mapping")

        if confirmed:
            st.session_state.mapped_df = user_df.rename(
                columns={
                    subj_sel: "Subject",
                    samp_sel: "Sample",
                    repl_sel: "Replicate",
                    res_sel:  "Result",
                }
            )
            st.success("Mapping saved â€“ you can now calculate.")

    # NEW â€“ user option: CV-ANOVA
    estimate_cv_anova = st.checkbox("Estimate CVI with CV-ANOVA")
    st.session_state["use_cv_anova"] = estimate_cv_anova

    if st.button("Calculate", type="primary"):
        try:
            df_for_calc = st.session_state.get("mapped_df")
            if df_for_calc is None:
                st.warning("Please open â€œMap / confirm columnsâ€ and save a mapping first.")
                st.stop()                       # abort this run cleanly

            try:
                res = calculate_bv(
                    df_for_calc,
                    use_cv_anova=st.session_state.get("use_cv_anova", False),
                    enforce_balance = st.session_state.get("enforce_balance", True)   # NEW
                )


                # Key metrics â€” big bold labels, smaller numbers
                #  Key metrics â€“ two-row layout
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.subheader("Key metrics")

                # --- build the metrics list ---
                metrics = [
                    ("Mean",
                    f"{res.grand_mean:.2f}",
                    f"{res.ci_mean[0]:.2f}â€“{res.ci_mean[1]:.2f} CI"),
                    ("CV<sub>A</sub>",
                    f"{res.cv_A:.2f}Â %",
                    f"{res.ci_cv_A[0]:.2f}â€“{res.ci_cv_A[1]:.2f}% CI"),
                    ("CV<sub>I</sub> <span style='font-size:0.7em;'>(based on standard ANOVA)</span>",
                        f"{res.cv_I:.2f} %",
                        f"{res.ci_cv_I[0]:.2f}â€“{res.ci_cv_I[1]:.2f}% CI"),
                    ("CV<sub>G</sub>",  f"{res.cv_G:.2f} %",
                        f"{res.ci_cv_G[0]:.2f}â€“{res.ci_cv_G[1]:.2f}% CI"),
                    ("95â€‰% RCV",        f"Â±{res.rcv_95:.2f} %",                                    None),
                ]

                # append the optional CV-ANOVA metric as *last* element
                if res.cv_I_cv_anova is not None:
                    metrics.append((
                        "CV<sub>I</sub> <span style='font-size:0.75em;'>(based on CV-ANOVA)</span>",
                        f"{res.cv_I_cv_anova:.2f} %",
                        f"{res.ci_cv_I_cv_anova[0]:.2f}â€“{res.ci_cv_I_cv_anova[1]:.2f}% CI"
                    ))

                # --- split into rows ------------------------------------------------------
                first_row  = metrics[:-3]                     # everything except the very last
                second_row = metrics[-3:]                    # the last metric (may be empty)

                # helper that renders one row of â€œcardsâ€
                def _render_row(row_metrics):
                    cols = st.columns(len(row_metrics), gap="large")
                    for col, (label, value, delta) in zip(cols, row_metrics):
                        with col:
                            st.markdown(f"""
                            <div style="
                                background:#f0f0f3; border-radius:1rem; padding:0.8rem 1rem;
                                text-align:center;
                                box-shadow:6px 6px 12px rgba(0,0,0,0.12),
                                        -6px -6px 12px rgba(255,255,255,0.85);
                            ">
                            <div style="font-size:1.4rem; font-weight:800; color:#1e3a5f;
                                        line-height:1.1; margin-bottom:0.15rem;">
                                {label}
                            </div>
                            <div style="font-size:1rem; font-weight:600; color:#1b263b;
                                        line-height:1.2;">{value}</div>
                            {f"<div style='font-size:0.75rem; color:#5d6d7e; margin-top:0.3rem;'>{delta}</div>" if delta else ""}
                            </div>
                            """, unsafe_allow_html=True)

                # draw the two rows
                _render_row(first_row)
                if second_row:                               
                    st.write(" ")
                    st.write(" ")
                    _render_row(second_row)


                # Summary table of CVs and 95% CIs
                st.write(" ")
                st.write(" ")
                st.subheader("Summary of variation metrics")
                var_tbl = pd.DataFrame({
                    "Component": ["Analytical", "Withinâ€‘subject", "Betweenâ€‘subject"],
                    "Variance":  [res.var_A,    res.var_WP,      res.var_BP],
                    "CV %":      [res.cv_A,     res.cv_I,        res.cv_G],
                    "95 % CI":   [f"{res.ci_cv_A[0]:.2f}â€“{res.ci_cv_A[1]:.2f}Â %",
                                f"{res.ci_cv_I[0]:.2f}â€“{res.ci_cv_I[1]:.2f}Â %",
                                f"{res.ci_cv_G[0]:.2f}â€“{res.ci_cv_G[1]:.2f}Â %"],
                })

                st.dataframe(
                    var_tbl.style
                        .format({"Variance": "{:.3f}", "CV %": "{:.2f}"})
                        .set_table_styles([{
                            "selector": "th",
                            "props": [("background-color", "#d0e7f5"),
                                        ("color", "#1e3a5f"),
                                        ("font-size", "0.9rem")]
                        }]),
                    hide_index=True,
                    use_container_width=True
                )



                # â€” Per-subject mean Â± range plot â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
                clean_df, _ = _preprocess_bv_dataframe(
                    df_for_calc,
                    flags=st.session_state["preproc_flags"],      # â† add
                    enforce_balance=st.session_state["enforce_balance"]
                )
                st.subheader("Per-subject distribution")
                st.plotly_chart(plot_subject_ranges(clean_df), use_container_width=True)


                # ---------------------------------------------------------------------------
                #  ğŸ“‹  BIVAC CHECKLIST  (QIâ€¯6Â â†’Â QIâ€¯14)
                #      â€“ fills Comment / Details and skips QIâ€¯1â€‘5
                # ---------------------------------------------------------------------------
                import re
                from collections import defaultdict

                def _build_qi_checklist(
                        log_lines: list[str],
                        res: BVResult,
                        flags: dict[str, bool],
                ) -> pd.DataFrame:
                    """
                    Build a BIVAC v1.1 checklist exactly as defined in Aarsandâ€¯etâ€¯al. 2018,
                    but **only for QIâ€¯6â€‘14** and with 2 new features:

                    â€¢ *Comment*  â€“ short humanâ€‘readable explanation of the grade  
                    â€¢ *Details*  â€“ concatenation of **all** log lines relevant to that QI  

                    Critical items (6â€‘8â€‘10â€‘11â€‘13) still autoâ€‘downgrade to D when they
                    would otherwise have received C (see Tableâ€¯1 of the paper).
                    """

                    # ------------------------------------------------------------------ helpers
                    def worst(g1, g2):                        # strict min on the A>B>C>D scale
                        order = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
                        return g1 if order[g1] >= order[g2] else g2

                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # 1.  Grade assessment  (same logic you already had, but no QIâ€¯1â€‘5)
                    #    â€“â€“â€“â€“â€“ I moved the old logic into a small dict for clarity â€“â€“â€“â€“â€“
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    grade, comment = {}, {}       # QI âœ grade / comment (Aâ€“D)

                    # ---------- QIâ€¯6  (replicates / analytical imprecision) -----------------
                    grade["6"]   = "A" if res.R >= 2 else "C"
                    comment["6"] = f"{res.R} replicates per sample detected."
                    # ---------- QIâ€¯7  (steadyâ€‘state / drift) --------------------------------
                    drift = any("temporal drift" in l.lower() for l in log_lines)
                    grade["7"]   = "A"
                    comment["7"] = "Significant drift subjects removed." if drift else "No drift detected."
                    # ---------- QIâ€¯8  (outlier handling) ------------------------------------
                    rep_ok  = flags.get("rep_cochran", True)
                    samp_ok = flags.get("samp_cochran", True)
                    subj_ok = flags.get("reed",        True)

                    if rep_ok and samp_ok and subj_ok:
                        grade["8"] = "A"
                        comment["8"] = "Replicate, sample and subjectâ€‘level outlier tests performed."
                    elif samp_ok and subj_ok:
                        grade["8"] = "B"
                        comment["8"] = "Replicateâ€‘level outlier test skipped."
                    elif samp_ok:
                        grade["8"] = "B"
                        comment["8"] = "Replicateâ€‘ & subjectâ€‘level outlier tests skipped."
                    else:
                        grade["8"] = "C"
                        comment["8"] = "Only partial outlier testing."
                    # ---------- QIâ€¯9  (normality) ------------------------------------------
                    transformed = any("log transform applied" in l.lower() for l in log_lines)
                    grade["9"]   = "A"
                    comment["9"] = "Logâ€‘transform applied." if transformed else "Gaussian on raw scale."
                    # ---------- QIâ€¯10 (variance homogeneity) -------------------------------
                    het = any("heterogeneous" in l.lower() for l in log_lines)
                    if not flags.get("wp_bartlett", True):
                        grade["10"] = "B"
                        comment["10"] = "Variance homogeneity test skipped."
                    else:
                        grade["10"] = "A" if not het else "C"
                        comment["10"] = "Variances homogeneous." if not het else "Heterogeneous variances."
                    # ---------- QIâ€¯11 (ANOVA model) ----------------------------------------
                    balanced = res.S == int(res.S) and res.R == int(res.R)
                    grade["11"]   = "A" if balanced else "B"
                    comment["11"] = "Balanced nested ANOVA." if balanced else "Methodâ€‘ofâ€‘moments (unbalanced)."
                    # ---------- QIâ€¯12 (confidence limits) ----------------------------------
                    grade["12"]   = "A"
                    comment["12"] = "95â€¯% CIs on CVA/CVI/CVG reported."
                    # ---------- QIâ€¯13 (numbers kept) ---------------------------------------
                    grade["13"]   = "A"
                    kept = res.I * res.S * res.R
                    comment["13"] = f"{kept} results retained after QC."
                    # ---------- QIâ€¯14 (mean concentration) ---------------------------------
                    grade["14"]   = "A"
                    comment["14"] = f"Mean concentration {res.grand_mean:.2f}."

                    # ------------------------------------------------------------------ autoâ€‘downgrade critical items to D
                    for q in ("6", "8", "10", "11", "13"):
                        if grade[q] == "C":
                            grade[q] = "D"
                            comment[q] += "  (critical item downgraded to D)"

                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # 2.  Map preprocessing log â†’ Details column
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # simple pattern map: QI âœ keywords expected in that log line
                    patterns = {
                        "6": ("cvâ‚", "analytical imprecision"),
                        "7": ("drift",),
                        "8": ("outlier",),
                        "9": ("normality", "log transform"),
                        "10": ("bartlett", "heterogeneous"),
                        "11": ("balanced", "unbalanced", "anova"),
                        "13": ("subject", "sample", "replicate", "results retained"),
                        "14": ("mean",),
                        # QIâ€¯12 has no explicit log hooks â€“ weâ€™ll leave Details blank
                    }

                    details = defaultdict(list)
                    for line in log_lines:
                        line_l = line.lower()
                        for q, keys in patterns.items():
                            if any(k in line_l for k in keys):
                                details[q].append(line)

                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # 3.  Assemble DataFrame (QIâ€¯6â€‘14) and overall grade
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    rows, overall = [], "A"
                    for q in map(str, range(6, 15)):
                        overall = worst(overall, grade[q])
                        rows.append(dict(
                            QI      = f"QIÂ {q}",
                            Grade   = grade[q],
                            Comment = comment[q],
                            Details = " âµ ".join(details.get(q, []))          # nice arrow separator
                        ))

                    df = pd.DataFrame(rows)
                    df.attrs["overall_grade"] = overall
                    return df




                # â”€â”€ render the checklist & XLSX download â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.subheader("BIVAC Checklist (QI 6 â†’ QI 14)")
                bivac_df = _build_qi_checklist(
                    res.preprocess_log,
                    res,
                    flags = st.session_state["preproc_flags"]
                )

                st.dataframe(
                    bivac_df.style.apply(
                        lambda s: ["background:#e8f9f0" if g in ("A", "B") else
                                "background:#fdecea"   for g in s],
                        axis=1, subset=["Grade"]
                    ).set_properties(**{"font-size": "0.85rem"}),
                    use_container_width=True,
                    hide_index=True,
                )
                overall = bivac_df.attrs["overall_grade"]
                st.markdown(f"**Overall BIVAC grade:Â {overall}**")

                # â¬‡ï¸  Excel export (tries xlsxwriter â†’ falls back to openpyxl)
                with st.expander("â‡¢ Download checklist"):
                    import io, importlib
                    engine = "xlsxwriter" if importlib.util.find_spec("xlsxwriter") else "openpyxl"

                    xio = io.BytesIO()
                    with pd.ExcelWriter(xio, engine=engine) as xl:
                        bivac_df.to_excel(xl, index=False, sheet_name="BIVAC_QI_6-13")

                    st.download_button(
                        "Excel file",
                        data=xio.getvalue(),
                        file_name="BIVAC_QI_6-13.xlsx",
                        mime=(
                            "application/vnd.openxmlformats-officedocument."
                            "spreadsheetml.sheet"
                        ),
                    )


                # â€” Outlier / normality audit trail â€”
                with st.expander("Pre-processing log"):
                    if res.preprocess_log:
                        for line in res.preprocess_log:
                            st.write("â€¢", line)
                    else:
                        st.write("No outliers detected; data met normality assumptions.")

            except PreprocessError as e:
                st.error(e.args[0])                      # friendly headline
                st.subheader("Quality-Improvement log (all steps)")
                for line in e.log:
                    st.write("â€¢", line)                  # bullet list
            except Exception as e:
                st.write(e)
                st.error(f"Calculation failed: {e}")     # any other unexpected error

        except Exception as e:
            st.write(e)
            st.error(f"Calculation failed: {e}")
else:
    st.info("Input data above to enable calculation.")
